{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 传统的embedding\n",
    "\n",
    "典型代表：\n",
    "\n",
    "* word2vec\n",
    "* GloVe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## word2vec\n",
    "\n",
    "[illustrated-word2vec](https://jalammar.github.io/illustrated-word2vec/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GloVe\n",
    "\n",
    "[GloVe paper](https://arxiv.org/abs/1610.03759)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contextual Embedding\n",
    "\n",
    "\n",
    "[A Survey on Contextual Embeddings](https://arxiv.org/pdf/2003.07278.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "传统的embedding，例如word2vec，Glove等，对于每一个token仅有一个全局固定的表示，忽略了上下文。\n",
    "\n",
    "Contextual embedding可以根据token的不同上下文获得不同的向量表示。\n",
    "\n",
    "\n",
    "Contextual embedding是一个**整个输入序列**的函数。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "获得contextual embedding的主要方法是**语言模型**。\n",
    "\n",
    "语言模型是一个序列的概率分布。以下几个概念等价：\n",
    "\n",
    "* 预测下一个词语\n",
    "* 整个序列的联合概率\n",
    "\n",
    "$$p(t_1,t_2,...,t_N) = \\prod_{i=1}^{N}p(t_i|t_1,t_2,...,t_{i-1})$$\n",
    "\n",
    "上式即：**联合概率**和**条件概率**之间的关系\n",
    "\n",
    "\n",
    "语言模型通常使用**最大似然估计（MSE）** 和 **正则化** 来估算模型参数。\n",
    "\n",
    "\n",
    "**条件概率**通常通过神经网络来学习得到。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ELMo\n",
    "\n",
    "[Deep contextualized word representations](https://arxiv.org/pdf/1802.05365.pdf)\n",
    "[The Illustrated BERT, ELMo, and co.](https://jalammar.github.io/illustrated-bert/)\n",
    "\n",
    "ELMo通过**预测下一个词语（即语言模型）** 来获得词语的向量表示。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sent2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## doc2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:machine-learning-notes] *",
   "language": "python",
   "name": "conda-env-machine-learning-notes-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
